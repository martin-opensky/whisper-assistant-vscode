{
  "name": "whisper-assistant",
  "displayName": "Whisper Assistant",
  "description": "Leveraging OpenAI's Whisper to transcribe your speech, enhancing your coding efficiency and experience.",
  "version": "1.2.4",
  "publisher": "MartinOpenSky",
  "icon": "images/whisper-assistant.png",
  "repository": {
    "type": "git",
    "url": "https://github.com/martin-opensky/whisper-assistant-vscode.git"
  },
  "engines": {
    "vscode": "^1.70.0"
  },
  "categories": [
    "Other"
  ],
  "activationEvents": [
    "onStartupFinished",
    "onDidChangeWorkspaceFolders"
  ],
  "main": "./out/extension.js",
  "contributes": {
    "commands": [
      {
        "command": "whisperAssistant.toggleRecording",
        "title": "Toggle Recording"
      }
    ],
    "keybindings": [
      {
        "command": "whisperAssistant.toggleRecording",
        "key": "ctrl+m",
        "mac": "cmd+m"
      }
    ],
    "configuration": {
      "type": "object",
      "title": "Whisper Assistant Settings",
      "properties": {
        "whisper-assistant.apiProvider": {
          "type": "string",
          "default": "localhost",
          "enum": [
            "localhost",
            "openai",
            "groq"
          ],
          "description": "Select the API provider for transcription"
        },
        "whisper-assistant.apiKey": {
          "type": "string",
          "default": "localhost-key-must-be-set",
          "description": "API key for the selected provider (must be set for localhost)"
        },
        "whisper-assistant.customEndpoint": {
          "type": "string",
          "default": "http://localhost:4444",
          "description": "Custom endpoint URL (localhost only)"
        },
        "whisper-assistant.customRecordingCommand": {
          "type": "string",
          "default": "",
          "description": "Custom recording command (must include $AUDIO_FILE placeholder). Leave empty to use sox (default). Example for macOS: 'ffmpeg -f avfoundation -i :1 -ac 1 -ar 16000 -sample_fmt s16 $AUDIO_FILE'"
        },
        "whisper-assistant.model": {
          "type": ["string", "null"],
          "default": null,
          "description": "Specify the Whisper model to use for transcription. Leave as null to use the provider's default model. Examples: 'whisper-1', 'whisper-large-v3-turbo', or any other model supported by your provider."
        },
        "whisper-assistant.transcriptionLanguage": {
          "type": "string",
          "enum": [
            "Auto",
            "English",
            "Chinese",
            "German",
            "Spanish",
            "Russian",
            "Korean",
            "French",
            "Japanese",
            "Portuguese",
            "Turkish",
            "Polish",
            "Catalan",
            "Dutch",
            "Arabic",
            "Swedish",
            "Italian",
            "Indonesian",
            "Hindi",
            "Finnish",
            "Vietnamese",
            "Hebrew",
            "Ukrainian",
            "Greek",
            "Malay",
            "Czech",
            "Romanian",
            "Danish",
            "Hungarian",
            "Tamil",
            "Norwegian",
            "Thai",
            "Urdu",
            "Croatian",
            "Bulgarian",
            "Lithuanian",
            "Latin",
            "Malayalam",
            "Welsh",
            "Slovak",
            "Telugu",
            "Persian",
            "Latvian",
            "Bengali",
            "Serbian",
            "Azerbaijani",
            "Slovenian",
            "Kannada",
            "Estonian",
            "Macedonian",
            "Breton",
            "Basque",
            "Icelandic",
            "Armenian",
            "Nepali",
            "Mongolian",
            "Bosnian",
            "Kazakh",
            "Albanian",
            "Swahili",
            "Galician",
            "Marathi",
            "Punjabi",
            "Sinhala",
            "Khmer",
            "Shona",
            "Yoruba",
            "Somali",
            "Afrikaans",
            "Occitan",
            "Georgian",
            "Belarusian",
            "Tajik",
            "Sindhi",
            "Gujarati",
            "Amharic",
            "Yiddish",
            "Lao",
            "Uzbek",
            "Faroese",
            "Haitiancreole",
            "Pashto",
            "Turkmen",
            "Nynorsk",
            "Maltese",
            "Sanskrit",
            "Luxembourgish",
            "Myanmar",
            "Tibetan",
            "Tagalog",
            "Malagasy",
            "Assamese",
            "Tatar",
            "Hawaiian",
            "Lingala",
            "Hausa",
            "Bashkir",
            "Javanese",
            "Sundanese",
            "Cantonese"
          ],
          "default": "English",
          "description": "Transcription language. Use Auto to automatically detect spoken language."
        }
      }
    }
  },
  "scripts": {
    "vscode:prepublish": "yarn run compile",
    "compile": "tsc -p ./",
    "watch": "tsc -watch -p ./",
    "pretest": "yarn run compile && yarn run lint && rm -rf .vscode-test",
    "lint": "eslint src --ext ts",
    "test": "node ./out/test/runTest.js",
    "package": "vsce package",
    "publish": "vsce package && vsce publish",
    "clean": "rm -rf out .vscode-test"
  },
  "devDependencies": {
    "@types/mocha": "^10.0.1",
    "@types/node": "16.x",
    "@types/vscode": "^1.70.0",
    "@typescript-eslint/eslint-plugin": "^6.4.1",
    "@typescript-eslint/parser": "^6.4.1",
    "@vscode/test-electron": "^2.3.4",
    "@vscode/vsce": "^2.24.0",
    "eslint": "^8.47.0",
    "glob": "^10.3.3",
    "mocha": "^10.2.0",
    "openai": "^4.90.0",
    "typescript": "^5.1.6"
  },
  "dependencies": {
    "openai": "^4.90.0"
  }
}
